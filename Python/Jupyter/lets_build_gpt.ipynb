{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd30def-41d7-4e9e-bdd9-242af621c5d1",
   "metadata": {},
   "source": [
    "# Lets build GPT by Andrej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19cd5dbe-b655-48bd-90ed-88fcd3eccca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c12ba212-cf87-416e-89a7-93f21c320d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e677c8a-9b96-4406-878a-03ab0719e093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89bed5d6-aae7-439f-83f8-df8db58ee22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71, 4178, 289, 21065, 23105, 612]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.encode(\"hii h ii hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d3b7c8-b53f-4b2b-a077-11865c2fef66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71     :h\n",
      "\n",
      "4178   :ii\n",
      "\n",
      "289    : h\n",
      "\n",
      "21065  : ii\n",
      "\n",
      "23105  : hi\n",
      "\n",
      "612    : there\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\n'.join([f'{i:<7}:{enc.decode([i])}' for i in [71, 4178, 289, 21065, 23105, 612]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17116d53-69fc-423a-ab64-e99ff3c8f191",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'dataset/esenin-royallib.ru.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5db738d1-0ebd-4c6a-8a66-82998bd06bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20d5d286-518b-4a35-a5e2-12e75c350af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt file length: 249624\n"
     ]
    }
   ],
   "source": [
    "print(f'txt file length: {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee95662d-be6b-4b8b-ab08-765d126c1a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вот уж вечер. Роса\n",
      "Блестит на крапиве.\n",
      "Я стою у дороги,\n",
      "Прислонившись к иве.\n",
      "\n",
      "От луны свет большой\n",
      "Прямо на нашу крышу.\n",
      "Где-то песнь соловья\n",
      "Вдалеке я слышу.\n",
      "\n",
      "Хорошо и тепло,\n",
      "Как зимой у печки.\n",
      "И березы стоят,\n",
      "Как большие свечки.\n",
      "\n",
      "И вдали за рекой,\n",
      "Видно, за опушкой,\n",
      "Сонный сторож стучит\n",
      "Мертвой колотушкой.\n",
      "\n",
      "\n",
      "\n",
      "Там, где капустные грядки\n",
      "Красной водой поливает восход,\n",
      "Клененочек маленький матке\n",
      "Зеленое вымя сосет.\n",
      "\n",
      "Поет зима — аукает,\n",
      "Мохнатый лес баюкает\n",
      "Стозвоном сосняка.\n",
      "Кругом с тоской глубокою\n",
      "Плывут в страну далекую\n",
      "Седые облака.\n",
      "\n",
      "А по двору метелица\n",
      "Ковром шелковым стелется,\n",
      "Но больно холодна.\n",
      "Воробышки игривые,\n",
      "Как детки сиротливые,\n",
      "Прижались у окна.\n",
      "\n",
      "Озябли пташки малые,\n",
      "Голодные, усталые,\n",
      "И жмутся поплотней.\n",
      "А вьюга с ревом бешеным\n",
      "Стучит по ставням свешенным\n",
      "И злится все сильней.\n",
      "\n",
      "И дремлют пташки нежные\n",
      "Под эти вихри снежные\n",
      "У мерзлого окна.\n",
      "И снится им прекрасная,\n",
      "В улыбках солнца ясная\n",
      "Красавица весна.\n",
      "\n",
      "\n",
      "\n",
      "Ты поила коня из горстей в поводу,\n",
      "Отражаясь, березы ломались в пруду\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81fe847a-6ca8-4148-b488-25192ec3d7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !#&()*,-.0123456789:;<>?ims «»АБВГДЕЖЗИКЛМНОПРСТУФХЦЧШЩЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяё—…\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8674c6a-56f3-4cf8-aa08-d30845501f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 76, 68, 62, 65, 78, 1, 78, 79, 78]\n",
      "Привет тут\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l : ''.join([itos[i] for i in l])\n",
    "\n",
    "print(encode(\"Привет тут\"))\n",
    "print(decode(encode(\"Привет тут\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e4acce-1cf2-4b7d-ac0f-ae540b5e76ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([249624]) torch.int64\n",
      "tensor([34, 74, 78,  1, 79, 66,  1, 62, 65, 83, 65, 76, 10,  1, 47, 74, 77, 60,\n",
      "         0, 33, 71, 65, 77, 78, 68, 78,  1, 73, 60,  1, 70, 76, 60, 75, 68, 62,\n",
      "        65, 10,  0, 59,  1, 77, 78, 74, 90,  1, 79,  1, 64, 74, 76, 74, 63, 68,\n",
      "         8,  0, 46, 76, 68, 77, 71, 74, 73, 68, 62, 84, 68, 77, 88,  1, 70,  1,\n",
      "        68, 62, 65, 10,  0,  0, 45, 78,  1, 71, 79, 73, 87,  1, 77, 62, 65, 78,\n",
      "         1, 61, 74, 71, 88, 84, 74, 69,  0, 46, 76, 91, 72, 74,  1, 73, 60,  1,\n",
      "        73, 60, 84, 79,  1, 70, 76, 87, 84, 79, 10,  0, 35, 64, 65,  9, 78, 74,\n",
      "         1, 75, 65, 77, 73, 88,  1, 77, 74, 71, 74, 62, 88, 91,  0, 34, 64, 60,\n",
      "        71, 65, 70, 65,  1, 91,  1, 77, 71, 87, 84, 79, 10,  0,  0, 52, 74, 76,\n",
      "        74, 84, 74,  1, 68,  1, 78, 65, 75, 71, 74,  8,  0, 41, 60, 70,  1, 67,\n",
      "        68, 72, 74, 69,  1, 79,  1, 75, 65, 83, 70, 68, 10,  0, 40,  1, 61, 65,\n",
      "        76, 65, 67, 87,  1, 77, 78, 74, 91, 78,  8,  0, 41, 60, 70,  1, 61, 74,\n",
      "        71, 88, 84, 68, 65,  1, 77, 62, 65, 83, 70, 68, 10,  0,  0, 40,  1, 62,\n",
      "        64, 60, 71, 68,  1, 67, 60,  1, 76, 65, 70, 74, 69,  8,  0, 34, 68, 64,\n",
      "        73, 74,  8,  1, 67, 60,  1, 74, 75, 79, 84, 70, 74, 69,  8,  0, 48, 74,\n",
      "        73, 73, 87, 69,  1, 77, 78, 74, 76, 74, 66,  1, 77, 78, 79, 83, 68, 78,\n",
      "         0, 43, 65, 76, 78, 62, 74, 69,  1, 70, 74, 71, 74, 78, 79, 84, 70, 74,\n",
      "        69, 10,  0,  0,  0,  0, 49, 60, 72,  8,  1, 63, 64, 65,  1, 70, 60, 75,\n",
      "        79, 77, 78, 73, 87, 65,  1, 63, 76, 91, 64, 70, 68,  0, 41, 76, 60, 77,\n",
      "        73, 74, 69,  1, 62, 74, 64, 74, 69,  1, 75, 74, 71, 68, 62, 60, 65, 78,\n",
      "         1, 62, 74, 77, 81, 74, 64,  8,  0, 41, 71, 65, 73, 65, 73, 74, 83, 65,\n",
      "        70,  1, 72, 60, 71, 65, 73, 88, 70, 68, 69,  1, 72, 60, 78, 70, 65,  0,\n",
      "        39, 65, 71, 65, 73, 74, 65,  1, 62, 87, 72, 91,  1, 77, 74, 77, 65, 78,\n",
      "        10,  0,  0, 46, 74, 65, 78,  1, 67, 68, 72, 60,  1, 93,  1, 60, 79, 70,\n",
      "        60, 65, 78,  8,  0, 43, 74, 81, 73, 60, 78, 87, 69,  1, 71, 65, 77,  1,\n",
      "        61, 60, 90, 70, 60, 65, 78,  0, 48, 78, 74, 67, 62, 74, 73, 74, 72,  1,\n",
      "        77, 74, 77, 73, 91, 70, 60, 10,  0, 41, 76, 79, 63, 74, 72,  1, 77,  1,\n",
      "        78, 74, 77, 70, 74, 69,  1, 63, 71, 79, 61, 74, 70, 74, 90,  0, 46, 71,\n",
      "        87, 62, 79, 78,  1, 62,  1, 77, 78, 76, 60, 73, 79,  1, 64, 60, 71, 65,\n",
      "        70, 79, 90,  0, 48, 65, 64, 87, 65,  1, 74, 61, 71, 60, 70, 60, 10,  0,\n",
      "         0, 32,  1, 75, 74,  1, 64, 62, 74, 76, 79,  1, 72, 65, 78, 65, 71, 68,\n",
      "        82, 60,  0, 41, 74, 62, 76, 74, 72,  1, 84, 65, 71, 70, 74, 62, 87, 72,\n",
      "         1, 77, 78, 65, 71, 65, 78, 77, 91,  8,  0, 44, 74,  1, 61, 74, 71, 88,\n",
      "        73, 74,  1, 81, 74, 71, 74, 64, 73, 60, 10,  0, 34, 74, 76, 74, 61, 87,\n",
      "        84, 70, 68,  1, 68, 63, 76, 68, 62, 87, 65,  8,  0, 41, 60, 70,  1, 64,\n",
      "        65, 78, 70, 68,  1, 77, 68, 76, 74, 78, 71, 68, 62, 87, 65,  8,  0, 46,\n",
      "        76, 68, 66, 60, 71, 68, 77, 88,  1, 79,  1, 74, 70, 73, 60, 10,  0,  0,\n",
      "        45, 67, 91, 61, 71, 68,  1, 75, 78, 60, 84, 70, 68,  1, 72, 60, 71, 87,\n",
      "        65,  8,  0, 35, 74, 71, 74, 64, 73, 87, 65,  8,  1, 79, 77, 78, 60, 71,\n",
      "        87, 65,  8,  0, 40,  1, 66, 72, 79, 78, 77, 91,  1, 75, 74, 75, 71, 74,\n",
      "        78, 73, 65, 69, 10,  0, 32,  1, 62, 88, 90, 63, 60,  1, 77,  1, 76, 65,\n",
      "        62, 74, 72,  1, 61, 65, 84, 65, 73, 87, 72,  0, 48, 78, 79, 83, 68, 78,\n",
      "         1, 75, 74,  1, 77, 78, 60, 62, 73, 91, 72,  1, 77, 62, 65, 84, 65, 73,\n",
      "        73, 87, 72,  0, 40,  1, 67, 71, 68, 78, 77, 91,  1, 62, 77, 65,  1, 77,\n",
      "        68, 71, 88, 73, 65, 69, 10,  0,  0, 40,  1, 64, 76, 65, 72, 71, 90, 78,\n",
      "         1, 75, 78, 60, 84, 70, 68,  1, 73, 65, 66, 73, 87, 65,  0, 46, 74, 64,\n",
      "         1, 89, 78, 68,  1, 62, 68, 81, 76, 68,  1, 77, 73, 65, 66, 73, 87, 65,\n",
      "         0, 50,  1, 72, 65, 76, 67, 71, 74, 63, 74,  1, 74, 70, 73, 60, 10,  0,\n",
      "        40,  1, 77, 73, 68, 78, 77, 91,  1, 68, 72,  1, 75, 76, 65, 70, 76, 60,\n",
      "        77, 73, 60, 91,  8,  0, 34,  1, 79, 71, 87, 61, 70, 60, 81,  1, 77, 74,\n",
      "        71, 73, 82, 60,  1, 91, 77, 73, 60, 91,  0, 41, 76, 60, 77, 60, 62, 68,\n",
      "        82, 60,  1, 62, 65, 77, 73, 60, 10,  0,  0,  0,  0, 49, 87,  1, 75, 74,\n",
      "        68, 71, 60,  1, 70, 74, 73, 91,  1, 68, 67,  1, 63, 74, 76, 77, 78, 65,\n",
      "        69,  1, 62,  1, 75, 74, 62, 74, 64, 79,  8,  0, 45, 78, 76, 60, 66, 60,\n",
      "        91, 77, 88,  8,  1, 61, 65, 76, 65, 67, 87,  1, 71, 74, 72, 60, 71, 68,\n",
      "        77, 88,  1, 62,  1, 75, 76, 79, 64, 79])\n"
     ]
    }
   ],
   "source": [
    "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
    "import torch # we use PyTorch: https://pytorch.org\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b236f191-7b8d-49e2-bea6-b255ce0bce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c262923c-188f-410f-98b7-d0948ee92201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([34, 74, 78,  1, 79, 66,  1, 62, 65])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8            # context length\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95c8c61f-751f-4f90-bba2-a50fdea63e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([34]) the target: 74\n",
      "when input is tensor([34, 74]) the target: 78\n",
      "when input is tensor([34, 74, 78]) the target: 1\n",
      "when input is tensor([34, 74, 78,  1]) the target: 79\n",
      "when input is tensor([34, 74, 78,  1, 79]) the target: 66\n",
      "when input is tensor([34, 74, 78,  1, 79, 66]) the target: 1\n",
      "when input is tensor([34, 74, 78,  1, 79, 66,  1]) the target: 62\n",
      "when input is tensor([34, 74, 78,  1, 79, 66,  1, 62]) the target: 65\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'when input is {context} the target: {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "095415ae-7dd7-44c3-a0ed-ccb2f22de8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[60, 71,  8,  0, 44, 65,  1, 78],\n",
      "        [ 0, 44, 65, 79, 66, 65, 71, 88],\n",
      "        [73, 88,  1, 68,  1, 67, 62, 65],\n",
      "        [60, 78, 74, 90,  1, 75, 65, 83]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[71,  8,  0, 44, 65,  1, 78, 74],\n",
      "        [44, 65, 79, 66, 65, 71, 88,  1],\n",
      "        [88,  1, 68,  1, 67, 62, 65, 73],\n",
      "        [78, 74, 90,  1, 75, 65, 83, 60]])\n",
      "----\n",
      "when input is [60] the target: 71\n",
      "when input is [60, 71] the target: 8\n",
      "when input is [60, 71, 8] the target: 0\n",
      "when input is [60, 71, 8, 0] the target: 44\n",
      "when input is [60, 71, 8, 0, 44] the target: 65\n",
      "when input is [60, 71, 8, 0, 44, 65] the target: 1\n",
      "when input is [60, 71, 8, 0, 44, 65, 1] the target: 78\n",
      "when input is [60, 71, 8, 0, 44, 65, 1, 78] the target: 74\n",
      "when input is [0] the target: 44\n",
      "when input is [0, 44] the target: 65\n",
      "when input is [0, 44, 65] the target: 79\n",
      "when input is [0, 44, 65, 79] the target: 66\n",
      "when input is [0, 44, 65, 79, 66] the target: 65\n",
      "when input is [0, 44, 65, 79, 66, 65] the target: 71\n",
      "when input is [0, 44, 65, 79, 66, 65, 71] the target: 88\n",
      "when input is [0, 44, 65, 79, 66, 65, 71, 88] the target: 1\n",
      "when input is [73] the target: 88\n",
      "when input is [73, 88] the target: 1\n",
      "when input is [73, 88, 1] the target: 68\n",
      "when input is [73, 88, 1, 68] the target: 1\n",
      "when input is [73, 88, 1, 68, 1] the target: 67\n",
      "when input is [73, 88, 1, 68, 1, 67] the target: 62\n",
      "when input is [73, 88, 1, 68, 1, 67, 62] the target: 65\n",
      "when input is [73, 88, 1, 68, 1, 67, 62, 65] the target: 73\n",
      "when input is [60] the target: 78\n",
      "when input is [60, 78] the target: 74\n",
      "when input is [60, 78, 74] the target: 90\n",
      "when input is [60, 78, 74, 90] the target: 1\n",
      "when input is [60, 78, 74, 90, 1] the target: 75\n",
      "when input is [60, 78, 74, 90, 1, 75] the target: 65\n",
      "when input is [60, 78, 74, 90, 1, 75, 65] the target: 83\n",
      "when input is [60, 78, 74, 90, 1, 75, 65, 83] the target: 60\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f'when input is {context.tolist()} the target: {target}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abb38ac6-518e-48e0-a0c3-45526478ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "tensor(5.1501, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "»Ю;6;«Я«.29еm 1ф4эайн-б!?ЯЭЖЗ#иН&Кпс; У!кЯУ:рёыых;М:СПм)НхОятБ,жв6джЖе(фьффт#К*\n",
      "8ияр2оя1Шн?&кБД4mНЖ7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # B x 1\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  #  B x T+1\n",
    "        return idx\n",
    "        \n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(loss.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5042632-3da5-4aad-bcfd-e1454343e132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5539])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#expected loss (analytically)\n",
    "-torch.log(torch.tensor([1/vocab_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d121a24c-bc1c-4857-b9ff-57eadbe2fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(m.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91e4c858-a55c-45fd-af2b-74126cc71185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.614084482192993\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100000):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1f2151f-2426-46e6-97b7-cbde52a00870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Пре:\n",
      "Пра я ващист устодилась енег я о ре\n",
      "Наштовастют\n",
      "Скрю\n",
      "Нед х,\n",
      "Узероренот\n",
      "И жьстотемеру,\n",
      "Чтроны, говый пометубожиниястешатьк пе Госк лоя рнаки прыхо в масть веслолоды лийче,\n",
      "И ль.\n",
      "Вья, от претило пая босто нон уй сошалиедясонуй яц! выбость м всмуй гопороте ст снишаю,\n",
      "Проливенают, ром,\n",
      "Недазмадрел\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5cff133-b209-4147-99ba-c724c14b4c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring averaging out the previous by t (beeeee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a20e1ba-f596-42b3-8c69-da7e66a9afa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5904402-3ab9-435e-b6ea-3996718a94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow[b,t] = torch.mean(xprev,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e44d053b-c9fc-4281-b9de-51167cad336c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb47162-8e7b-45cd-a118-e8608abb79a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
